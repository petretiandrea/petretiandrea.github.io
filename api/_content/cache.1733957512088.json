{"generatedAt":1733957527478,"generateTime":563,"contents":[{"_path":"/blog/design-distributed-scheduler-1","_dir":"blog","_draft":false,"_partial":false,"_locale":"","title":"Design Distributed Scheduler - I","description":"This article explores the design of a distributed scheduler optimized for scalability and fault tolerance. It covers key challenges like partitioning tasks, managing concurrency, and ensuring load distribution across multiple instances.","tags":["shard","partitions","scheduler","design","system architecture"],"date":"2024-12-11","image":"/blog/design-distributed-scheduler-1/images/thumbnail.webp","author":"Andrea Petreti","draft":false,"slug":"design-distributed-scheduler-1","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Having a distributed scheduler can be useful for orchestration purposes. For instance, it can be used to send a reminder after X minutes or enforce a workflow timeout (e.g., ensuring a payment is completed within Y minutes). However, designing a scheduler in a distributed environment is no trivial task, especially when aiming for high availability and scalability."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this design, I will focus primarily on the challenges of achieving scalability and high availability. To keep things straightforward, I will simplify the scheduler's requirements. For example, it will not handle retries for failed jobs, nor will it deal with job-specific concepts. Instead, the scheduler will operate on an abstract level with messages or commands. These messages or commands can be executed by any worker, potentially even the same worker that requested the scheduling."}]},{"type":"element","tag":"h2","props":{"id":"use-cases"},"children":[{"type":"text","value":"Use cases"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For this system let's assume the following use cases:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"user can schedule a message to be executed at given time"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"user can cancel a scheduled message"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"user can specify a channel (something similar to a kafka topic) where they want to receive the message"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Essentially, the system will function like a delayed queue, where messages are delivered at a specified time. When a message's time is up, the system will publish it to a real queue (e.g., Kafka, RabbitMQ)."}]},{"type":"element","tag":"h2","props":{"id":"big-picture-architecture"},"children":[{"type":"text","value":"Big picture architecture"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The main idea is to create a scheduler service which reads pending messages at given time, submit to queue and then track it's progress, like an offset. When a message is successfully delivered to destination topic then the scheduler update the message status (ack/nack)."}]},{"type":"element","tag":"img","props":{"src":"/blog/design-distributed-scheduler-1/images/big-picture.webp","alt":"big-picture","className":["center-md-image"],"width":500},"children":[]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Event the diagram shows multiple instance of scheduler service, this design start by\nexploring a solution based on single instance Scheduler and then starts by making some re-design\nto make system horizontally scalable."}]},{"type":"element","tag":"h2","props":{"id":"database"},"children":[{"type":"text","value":"Database"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"A robust database schema is a crucial element that directly impacts overall system performance. To optimize efficiency, we can start by splitting the read and write loads based on the system’s use cases."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"It’s easy to see that the primary type of load on the database is “read”. The scheduler will periodically (e.g., every X minutes) query the pending scheduled messages to determine which ones need to be submitted immediately."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"What about the write load? From the perspective of external actors, the system supports creating new scheduled messages or deleting existing ones. Internally, the scheduler also needs to update the status of messages once they are completed or have failed."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The key challenge is to design an efficient way to retrieve messages that are ready to be submitted. For this design, I’ll use MongoDB, a NoSQL database that enables easy scaling and partitioning of data."}]},{"type":"element","tag":"h3","props":{"id":"schema-design"},"children":[{"type":"text","value":"Schema design"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"A database schema for NoSQL like database"}]},{"type":"element","tag":"pre","props":{"className":"language-json shiki shiki-themes github-dark-dimmed","code":"{\n    \"scheduleId\": \"...\",\n    \"destinationTopic\": \"...\",\n    \"executionTime\": \"date-time\",\n    \"payload\": \"scheduled command payload\",\n    \"status\": \"PENDING|DELIVERED|DELIVERY_FAILED\"\n}\n","language":"json","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"{\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"scheduleId\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"...\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"destinationTopic\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"...\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"executionTime\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"date-time\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"payload\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"scheduled command payload\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"status\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"PENDING|DELIVERED|DELIVERY_FAILED\"\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"}\n"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The schema is pretty simple with few fields:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"payload"}]},{"type":"text","value":": Contains the data for the scheduled job. This payload will be delivered to the queue."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"status"}]},{"type":"text","value":": Tracks the schedule status. The default status is "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"PENDING"}]},{"type":"text","value":", while "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"DELIVERED"}]},{"type":"text","value":" means the message has been sent to the "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"destinationTopic"}]},{"type":"text","value":", and "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"DELIVERY_FAILED"}]},{"type":"text","value":" indicates a failure to deliver the message to the queue."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"executionTime"}]},{"type":"text","value":": A timestamp, rounded to the nearest minute or second, based on the scheduler’s granularity."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"destinationTopic"}]},{"type":"text","value":": Specifies the topic where the scheduler will publish the message. This could be a Kafka topic or a RabbitMQ routing key."}]}]},{"type":"element","tag":"h3","props":{"id":"storing-offset-and-execution-time"},"children":[{"type":"text","value":"Storing Offset and Execution Time"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In addition to the main scheduler collection, the system will have a dedicated collection to store the offset and the last "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"executionTime"}]},{"type":"text","value":". This will allow the scheduler to track the progress of scheduled messages more effectively.\nThe structure of this collection could look like this:"}]},{"type":"element","tag":"pre","props":{"className":"language-json shiki shiki-themes github-dark-dimmed","code":"{\n    \"lastExecutionTime\": \"date-time\"\n}\n","language":"json","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"{\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"lastExecutionTime\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"date-time\"\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"}\n"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Where:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"lastTaskId"}]},{"type":"text","value":": A unique identifier for the task being tracked."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"lastExecutionTime"}]},{"type":"text","value":": The last time the task was executed, helping to track the progress and avoid redundant processing."}]}]},{"type":"element","tag":"h3","props":{"id":"optimize-queries"},"children":[{"type":"text","value":"Optimize queries"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Example of SQL-like query to retrieve messages for next execution time. e.g. current "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"executionTime > 2024/09/25T12:50:00Z AND executionTime < 2024/09/25T12:50:00Z"}]}]},{"type":"element","tag":"pre","props":{"className":"language-sql shiki shiki-themes github-dark-dimmed","code":"SELECT * FROM schedules \nWHERE executionTime > {lastExecutionTime} \nAND executionTime < \"2024/09/25T12:50:01Z\" \n","language":"sql","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"SELECT"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":" *"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":" FROM"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" schedules \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"WHERE"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" executionTime "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":">"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" {lastExecutionTime} \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"AND"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" executionTime "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":" \"2024/09/25T12:50:01Z\"\n"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Why use a range query? It makes handling issues related to timestamp precision or small variations in service processing easier, especially in failure scenarios."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Without a proper data partition strategy, this query could result in a full scan of all shards. For example, if using "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"scheduleId"}]},{"type":"text","value":" as the shard key, running this query would span multiple partitions. To optimize the search query, a better shard key would be "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"executionTime"}]},{"type":"text","value":". This approach allows the query to be answered by exploring a single shard or a reduced number of shards. In MongoDB, this type of shard key is called a Range Shard Key. MongoDB automatically splits the data space into multiple ranges and redirects the request to the most appropriate shard or set of shards. From an abstract point of view, it's as if we are grouping all jobs with the same scheduling date into the same group."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The second operation involves updating the message status to either "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"DELIVERED"}]},{"type":"text","value":" or "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"DELIVERY_FAILED"}]},{"type":"text","value":".\nThis operation will use "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"scheduleId"}]},{"type":"text","value":" as the unique identifier. However, if we only use "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"executionTime"}]},{"type":"text","value":" as the shard key,\nthe write operation may lead to a scatter-gather query, which can reduce efficiency.\nTo improve performance, we can create a composite shard key by combining two keys.\nThis allows for more efficient updates by directing the operation to a specific shard."}]},{"type":"element","tag":"pre","props":{"className":"language-js shiki shiki-themes github-dark-dimmed","code":"db.shardCollection(\"messages\", {executionTime: 1, scheduleId: 1})\n","language":"js","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"db."}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#DCBDFB"},"children":[{"type":"text","value":"shardCollection"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"messages\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":", {executionTime: "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#6CB6FF"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":", scheduleId: "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#6CB6FF"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"})\n"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"With this composite shard key, the MongoDB query planner will target a single shard for each operation,\nimproving the performance and efficiency of writes. The first state in the query planner would be "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"SINGLE_SHARD"}]},{"type":"text","value":",\nmeaning the query no longer needs to perform a scatter-gather across multiple shards."}]},{"type":"element","tag":"h3","props":{"id":"dealing-with-skewed-partitions-and-hotspotting"},"children":[{"type":"text","value":"Dealing with Skewed Partitions and Hotspotting"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"What happens if many jobs are scheduled at the same time?\nIt depends on the granularity of the executionTime (e.g., rounding the timestamp to the second or minute),\nbut it could lead to "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"skewed partitions"}]},{"type":"text","value":".\nMongoDB also faces issues with Monotonic Increasing Keys, like timestamps, which can cause shard hotspotting.\nThis happens when new data constantly gets routed to the same shard due to a sequence of timestamps being close to each other.\nOver time, this leads to uneven load distribution and potential performance bottlenecks.\nWe will address how to resolve this issue in the next section when discussing the "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"scheduler-service"}]},{"type":"text","value":"."}]},{"type":"element","tag":"h2","props":{"id":"design-scheduler-service"},"children":[{"type":"text","value":"Design Scheduler service"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this first scheduler design, it's behaviour is quite  simple."}]},{"type":"element","tag":"ol","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"polling every minute/second for messages with "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"scheduledTime"}]},{"type":"text","value":" after last offeset"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"check if message is "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"PENDING"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"send a message to queue with payload"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"update job status based on queue’s publish outcome"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"checkpoint the offset by updating document."}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Optionally: To improve performance and reduce writes to the database, checkpointing can be performed every X seconds.\nThe downside of this approach is that the service could crash without writing its last checkpoint.\nWhen the service restarts, it will re-read the previous batch of messages,\nbut it won't produce duplicate messages due to the message status field."}]},{"type":"element","tag":"img","props":{"src":"/blog/design-distributed-scheduler-1/images/sequence.svg","alt":"sequence","className":["center-md-image"],"width":600},"children":[]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Obviously, the polling frequency determines the scheduler’s granularity.\nFor now, let's assume second-level granularity, even though this implies a lot of queries to the database.\nIn subsequent designs, I will explore ways to improve the system and reduce unnecessary queries\n(spoiler: using an actor-like approach and caching)."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The system seems ready for implementation, but what about horizontal scalability?\nIf I want to run multiple instances of the scheduler, this could lead to concurrency issues.\nFor example, two different instances might try to poll the same jobs and send the same events.\nAdditionally, there is no load distribution between instances!"}]},{"type":"element","tag":"h2","props":{"id":"re-design-make-it-scalable"},"children":[{"type":"text","value":"Re-Design: Make it scalable!"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Let's make a little bit of redesign to address some issues:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"High load for single worker when there are a lot of scheduled job at same second"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"The scheduler service cannot properly scale horizontally. Increasing instances doesn't distribute the load."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"The scheduler service is a single point of failure."}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The goal is to distribute the load at the application level. For example, if you have 10,000 jobs scheduled at the same time, we can split them into 10,000 / number of instances.\nThis way, each service will handle a different partition and poll only for its assigned partitions."}]},{"type":"element","tag":"h3","props":{"id":"database-1"},"children":[{"type":"text","value":"Database"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"At the database schema level, we need to introduce a new field: "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"bucket"}]},{"type":"text","value":".\nEach bucket can contain multiple scheduled messages at the same second. Suppose we define a total number of buckets (e.g. 20),\nthis means that messages scheduled at the same time can potentially be processed by a maximum of "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"20 parallel instances"}]},{"type":"text","value":".\nSo, the number of buckets is a hyperparameter that should be fine-tuned based on load expectations, something\nsimilar to the number of partitions in a Kafka topic."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So extend the schema in the following way:"}]},{"type":"element","tag":"pre","props":{"className":"language-json shiki shiki-themes github-dark-dimmed","code":"{ \n    \"scheduleId\": \"...\",\n    \"executionTime\": \"date-time\",\n    \"bucket\": 1,\n    \"payload\": \"scheduled command payload\",\n    \"status\": \"PENDING|DELIVERED|DELIVERY_FAILED\"\n}\n","language":"json","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"{ \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"scheduleId\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"...\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"executionTime\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"date-time\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"bucket\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#6CB6FF"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"payload\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"scheduled command payload\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#8DDB8C"},"children":[{"type":"text","value":"    \"status\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"PENDING|DELIVERED|DELIVERY_FAILED\"\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"}\n"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We can leverage the combination of "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"executionTime"}]},{"type":"text","value":" and "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"bucket"}]},{"type":"text","value":" as a composite shard key to improve and parallelize\nreads across multiple instances. Messages scheduled at the same time and in the same bucket will be colocated\nin the same MongoDB partition, which helps reduce partition skew for jobs scheduled at identical times."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"However, the MongoDB monotonic timestamp issue still persists. To mitigate this,\nusing "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"bucket"}]},{"type":"text","value":" as the shard key prefix (the first part of the composite key) can help reduce the negative effects\nof a monotonic timestamp:"}]},{"type":"element","tag":"pre","props":{"className":"language-js shiki shiki-themes github-dark-dimmed","code":"db.shardCollection(\"messages\", {bucket: \"hashed\", executionTime: 1, scheduleId: 1})\n","language":"js","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"db."}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#DCBDFB"},"children":[{"type":"text","value":"shardCollection"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"messages\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":", {bucket: "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":"\"hashed\""}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":", executionTime: "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#6CB6FF"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":", scheduleId: "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#6CB6FF"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"})\n"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Even though "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"bucket"}]},{"type":"text","value":" is a low-cardinality key, its combination with "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"executionTime"}]},{"type":"text","value":" (which is a high-cardinality and monotonic key)\nand "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"scheduleId"}]},{"type":"text","value":" (also a high-cardinality key) gives MongoDB enough information to effectively split the shards without issues. Additionally,\nusing a \"hashed\" "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"bucket"}]},{"type":"text","value":" ensures event data distribution across shards, thereby avoiding hotspotting.\nNow the query to retrieve next scheduled messages looks like the following one:"}]},{"type":"element","tag":"pre","props":{"className":"language-sql shiki shiki-themes github-dark-dimmed","code":"SELECT * FROM schedules \nWHERE bucket = {schedulerInstanceAssignedBucket} AND\nWHERE executionTime > {lastExecutionTime} \nAND executionTime < \"2024/09/25T12:50:01Z\"\n","language":"sql","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"SELECT"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":" *"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":" FROM"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" schedules \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"WHERE"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" bucket "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" {schedulerInstanceAssignedBucket} "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"AND\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"WHERE"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" executionTime "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":">"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" {lastExecutionTime} \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"AND"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" executionTime "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#96D0FF"},"children":[{"type":"text","value":" \"2024/09/25T12:50:01Z\"\n"}]}]}]}]},{"type":"element","tag":"h3","props":{"id":"scheduler-service"},"children":[{"type":"text","value":"Scheduler Service"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The re-design of scheduler service is not trivial, the idea is to split workload among multiple instances.\nFor example, fixed max of buckets to 20 and 4 scheduler instances, each scheduler should work on a specific assigned partitions.\nThe first one will handle the first 5 buckets, the second one from the second 5 buckets and so on."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"But what happens when a node fails? Or a new one is scaled-out? In such scenarios, the system requires rebalancing\nto ensure an even distribution of workloads. This calls for a coordination mechanism and cluster\nawareness to dynamically reassign buckets among the available nodes."}]},{"type":"element","tag":"h4","props":{"id":"clustering"},"children":[{"type":"text","value":"Clustering"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Typically, clusters involve "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"member discovery"}]},{"type":"text","value":" and "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"failure detection"}]},{"type":"text","value":" to update each instance’s local knowledge about the cluster. By knowing the cluster membership and the fixed bucket size, it becomes possible to assign (or self-assign) a set of partitions. Many techniques and technologies enable cluster formation and facilitate information sharing among members to split up partitions. For example:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Relying on Leader Election: Using consensus algorithms like Raft or Paxos, a leader is elected to assign partitions."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Zookeeper: Provides coordination and partition management."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Distributed Maps: High-level abstractions over consensus algorithms, like Hazelcast, that allow shared state and partition assignment."}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Another alternative - one I will explore and implement in the next article - is to use a cluster membership protocol combined with consistent hashing (hash ring)."}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"The membership protocol is responsible for detecting members in-out and node failures."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"The hash ring tracks active nodes on a logical ring and enables nodes to self-establish their own partitions. Additionally, the hash ring minimizes the number of partitions re-assignment during a rebalance."}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.toptal.com/big-data/consistent-hashing","rel":["nofollow"]},"children":[{"type":"text","value":"Consistent Hashing"}]},{"type":"text","value":" is an elegant solution for balancing workloads in distributed systems and will be a core component of the next design."}]},{"type":"element","tag":"callout","props":{"icon":"mdi:warning","type":"warning"},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"During scale-out, scale-in, or node failure, cluster members may temporarily see different member counts, leading to "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"partition ownership overlap"}]},{"type":"text","value":". To address this, the scheduler will rely on a persistence layer to acquire a "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"partition lock with fencing"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"These aspects, along with more details about application-level partitioning, hash rings, and membership protocols, will be deeply covered in the second part of \"Designing a Distributed Scheduler\"."}]}]},{"type":"element","tag":"h4","props":{"id":"message-bucket-assignment"},"children":[{"type":"text","value":"Message bucket assignment"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"How do we assign a bucket to a message? It's straightforward: by using a hash function or a round-robin policy.\nFor a hash-based approach, the assignment can be determined as follows:"}]},{"type":"element","tag":"pre","props":{"className":"language-js shiki shiki-themes github-dark-dimmed","code":"hash(scheduleId) % buckets\n","language":"js","meta":"","style":""},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"style":"--shiki-default:#DCBDFB"},"children":[{"type":"text","value":"hash"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":"(scheduleId) "}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#F47067"},"children":[{"type":"text","value":"%"}]},{"type":"element","tag":"span","props":{"style":"--shiki-default:#ADBAC7"},"children":[{"type":"text","value":" buckets\n"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Where scheduleId is a unique identifier, such as a UUID.\nWhile the hash function should be well-distributed, like MurMur3 (commonly used in Kafka).\nThis approach ensures that, given a specific "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"scheduleId"}]},{"type":"text","value":", the target "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"bucket"}]},{"type":"text","value":" can always be determined consistently. As a result, updating the message status can be optimized, avoiding scatter-gather queries in MongoDB."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The system effectively employs two layers of sharding:"}]},{"type":"element","tag":"ol","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Scheduler-To-Bucket"}]},{"type":"text","value":": Each worker is mapped inside a hash ring and is responsible for its assigned buckets."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Message-To-Bucket"}]},{"type":"text","value":": Each message is assigned to a specific bucket based on the hash function."}]}]},{"type":"element","tag":"img","props":{"src":"/blog/design-distributed-scheduler-1/images/message-partition-assignment.svg","alt":"message-partition-assignment","className":["center-md-image"],"width":700},"children":[]},{"type":"element","tag":"h2","props":{"id":"whats-next"},"children":[{"type":"text","value":"What’s Next?"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This article introduced the foundational design for a scalable, distributed scheduler. While we explored key concepts such as bucket-based sharding, partition ownership, and cluster coordination, there’s still more to uncover."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In the next article, I’ll delve deeper into:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Cluster membership and Hash Rings: Used to establish partition ownership to self-distribute workloads across nodes."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Partition Locking with Fencing Tokens: Approach to prevent ownership overlaps during transient states like scale-in, scale-out, or node failures."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Polling: Optimization to reduce every second polling on database."}]}]},{"type":"element","tag":"style","props":{},"children":[{"type":"text","value":"html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}"}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"use-cases","depth":2,"text":"Use cases"},{"id":"big-picture-architecture","depth":2,"text":"Big picture architecture"},{"id":"database","depth":2,"text":"Database","children":[{"id":"schema-design","depth":3,"text":"Schema design"},{"id":"storing-offset-and-execution-time","depth":3,"text":"Storing Offset and Execution Time"},{"id":"optimize-queries","depth":3,"text":"Optimize queries"},{"id":"dealing-with-skewed-partitions-and-hotspotting","depth":3,"text":"Dealing with Skewed Partitions and Hotspotting"}]},{"id":"design-scheduler-service","depth":2,"text":"Design Scheduler service"},{"id":"re-design-make-it-scalable","depth":2,"text":"Re-Design: Make it scalable!","children":[{"id":"database-1","depth":3,"text":"Database"},{"id":"scheduler-service","depth":3,"text":"Scheduler Service"}]},{"id":"whats-next","depth":2,"text":"What’s Next?"}]}},"_type":"markdown","_id":"content:blog:design-distributed-scheduler-1:index.md","_source":"content","_file":"blog/design-distributed-scheduler-1/index.md","_stem":"blog/design-distributed-scheduler-1/index","_extension":"md"},{"_path":"/blog/hello","_dir":"blog","_draft":false,"_partial":false,"_locale":"","title":"Hello!","description":"Welcome to my blog!","tags":["start"],"date":"2024-12-11","author":"Andrea Petreti","draft":false,"image":"/blog/hello/images/thumbnail.jpg","slug":"hello","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"hello"},"children":[{"type":"text","value":"Hello"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Welcome to my blog!"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This blog will serve two purposes: first, as a personal agenda to keep track of design patterns, strategies, and the thought process behind various technical decisions. Second, it will act as a platform to share these insights with others who might benefit from or challenge my ideas."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The focus here will be on architectural design, with a particular emphasis on systems that are both highly scalable and resilient."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"With experience in Quarkus, Spring Boot, Node.js, and a growing interest in Go and Rust, most of the solutions I’ll share will be based on these technologies."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:blog:hello:index.md","_source":"content","_file":"blog/hello/index.md","_stem":"blog/hello/index","_extension":"md"},{"_path":"/en/experiences","_dir":"en","_draft":false,"_partial":false,"_locale":"","experiences":[{"from":"06/01/2015","title":"Graduation in Computer Science","description":"ITIS E. Mattei Urbino \\\\ 86/110.","color":"orange","icon":"mdi:account-school"},{"from":"03/01/2018","title":"Full Stack Developer","description":"Sviluppatore full stack per dispositivi embedded legati all’industria 4.0 presso GreenDreams (startup).","color":"orange","icon":"mdi:briefcase"},{"from":"10/01/2018","title":"Bachelor's Degree in Computer Science","description":"Urbino University \\\\ 108/110.","color":"orange","icon":"mdi:account-school"},{"from":"03/01/2021","title":"Master's Degree in Computer Science and Software Engineering","description":"Bologna University (Cesena) \\ 110/110 with honors","color":"orange","icon":"mdi:account-school"},{"from":"05/13/2021","title":"Android and Flutter developer","color":"orange","icon":"mdi:briefcase","description":"Android (Java/Kotlin) and Flutter developer on Sysdata s.p.a. I have experience in both native and hybrid development with Flutter. The main technologies and languages I use are Kotlin with the new Compose framework and Flutter in mobile."},{"from":"06/20/2022","title":"Software Engineer","color":"orange","icon":"mdi:briefcase","currently":true,"description":"Software Engineer presso PagoPA s.p.a.\nWork on the design and development of microservice architectures.\n"}],"_id":"content:en:experiences.yaml","_type":"yaml","title":"Experiences","_source":"content","_file":"en/experiences.yaml","_stem":"en/experiences","_extension":"yaml"},{"_path":"/en/projects","_dir":"en","_draft":false,"_partial":false,"_locale":"","works":[{"title":"Home Assistant Tapo Integration","description":"With 700+ starts, tapo p100 is an integration for controlling smart plugs and smart lights of the [Tapo](https://www.tapo.com/en/) line through \nthe well-known home automation assistant [Home Assistant](https://www.home-assistant.io/). \nMade mainly in Python, this is the main integration used in the Home Assistant community. \n","thumbnail":"tapo-integration/thunmbnail.png","github":"https://github.com/petretiandrea/home-assistant-tapo-p100","tags":["home assistant","tapo","tplink","python","iot"]},{"title":"Beaesthetic Agenda","description":"Application and backend for appointment management of a beauty center. The system allows to manage clients,\nappointments and loyalty cards. It is also able to send notifications via Sms, Whatsapp and in the future push notification\nto customers to remind them of an appointment.\n","thumbnail":"beaesthetic/thumbnail.png","tags":["microservices","domain driven design","typescript","node"]},{"title":"Intelliserra","description":"Framework developed in Scala which allows managing smart greenhouse. It allows defining smart greenhouse through sensors and actuators and supports an event-based actuation rules system. \nThe main technologies used in this project are Scala, Akka and Prolog, and it developed with Marta Luffarelli, Simone Letizi and Ylenia Battistini.\n","thumbnail":"intelliserra/intelliserra.png","image_gallery":["intelliserra/intelliserra.png","intelliserra/intelliserra2.png"],"github":"https://github.com/sletizi/IntelliSerra","tags":["scala","functional","iot"]},{"title":"Scanbage","description":"A powerful web app to recognize types of garbage by photo or barcode through convolutional network (CNN Machine Learning).\nIt is a kind of social based on rewards unlocked through the correct differentiation of garbage. \nThe project has been realized in a university context with Gianluca Aguzzi, Marta Luffarelli and Simone Letizi.\n","thumbnail":"scanbage/thubnail.png","image_gallery":["scanbage/scanbage-pic1.png","scanbage/scanbage-pic2.png","scanbage/scanbage-pic3.png","scanbage/scanbage-pic4.png","scanbage/scanbage-pic5.png"],"tags":["machine learning","cnn","tensorflow","python"]},{"title":"Fluvium","description":"A full stack system for monitoring river rise levels. The system has been developed starting from embedded components (ESP32) up to the web/cloud layer based on AWS. \nThe project is realized in university context with Gianluca Aguzzi.\n","thumbnail":"fluvium/thubnail.png","image_gallery":["fluvium/screen1.png","fluvium/screen2.png","fluvium/screen3.png"],"github":"https://github.com/sbricco-house/fluvium","tags":["aws","iot","embedded","cloud"]},{"title":"Subspedia","description":"Mobile application for the subtitling website Subspedia <a target=_blank href=https://www.subspedia.tv/> subspedia.tv</a>. (now discontinued)\n","thumbnail":"subspedia/thubnail.png","image_gallery":["subspedia/pic1.png","subspedia/pic2.png","subspedia/pic3.png","subspedia/pic4.png"],"tags":["android","tv series","java"]}],"_id":"content:en:projects.yaml","_type":"yaml","title":"Projects","_source":"content","_file":"en/projects.yaml","_stem":"en/projects","_extension":"yaml"},{"_path":"/it/experiences","_dir":"it","_draft":false,"_partial":false,"_locale":"","experiences":[{"from":"06/01/2015","title":"Diploma","description":"Diploma in Informatica presso ITIS E.Mattei Urbino. \\\\ 86/110.","color":"orange","icon":"mdi:account-school"},{"from":"03/01/2018","title":"Full Stack Developer","description":"Sviluppatore full stack per dispositivi embedded legati all’industria 4.0 presso GreenDreams (startup).","color":"orange","icon":"mdi:briefcase"},{"from":"10/01/2018","title":"Laura triennale","description":"Laurea in Informatica applicata presso Università degli Studi di Urbino Carlo Bo. \\\\ 108/110.","color":"orange","icon":"mdi:account-school"},{"from":"03/01/2021","title":"Laura magistrale","description":"Laurea magistrale in Ingegneria e Scienze Informatiche presso Università di Bologna. \\\\ 110/110 e lode.","color":"orange","icon":"mdi:account-school"},{"from":"05/13/2021","title":"Android and Flutter developer","color":"orange","icon":"mdi:briefcase","description":"Sviluppatore Android (Java/Kotlin) e Flutter presso Sysdata s.p.a."},{"from":"06/20/2022","title":"Software Engineer","color":"orange","icon":"mdi:briefcase","currently":true,"description":"Software Engineer presso PagoPA s.p.a.\nWork on the design and development of microservice architectures.\n"}],"_id":"content:it:experiences.yaml","_type":"yaml","title":"Experiences","_source":"content","_file":"it/experiences.yaml","_stem":"it/experiences","_extension":"yaml"},{"_path":"/it/projects","_dir":"it","_draft":false,"_partial":false,"_locale":"","works":[{"title":"Home Assistant Tapo Integration","description":"Integrazione per l'hub domestico home assistant per controllare i dispositivi della gamma Tapo di Tp-Link.\nL'integrazione è sviluppata in Python ed è basata su una libreria da me realizzata per controllare i dispositivi Tapo. \nMolte persone ad oggi usano questa integrazione per controllare i dispositivi raggiungengo 600+ star su github e varie donazioni di supporto.\n","thumbnail":"tapo-integration/thunmbnail.png","github":"https://github.com/petretiandrea/home-assistant-tapo-p100","tags":["home assistant","tapo","tplink","python","iot"]},{"title":"Beaesthetic Agenda","description":"Applicazione e backend per la gestione di appuntamenti di un centro estetico. Il sistema permette di gestire clienti,\nappuntamenti e carte fedeltà. Inoltre è in grado di inviare notifiche via Sms, Whatsapp e in futuro push notification\nai clienti per ricordare un appuntamento.\n","thumbnail":"beaesthetic/thumbnail.png","tags":["microservices","domain driven design","typescript","node"]},{"title":"Intelliserra","description":"Framework per la gestione di serre intelligenti sviluppato in Scala. \nIl framwork consente di definire serre intelligenti attraverso sensori/attuatori e di poter definire regole di automazione basate su eventi. \nLe tecnologie utilizzate sono prevalentemente Scala, Akka e Prolog. Sviluppato in collaborazione con Marta Luffarelli e Simone Letizi e Ylenia Battistini.\n","thumbnail":"intelliserra/intelliserra.png","image_gallery":["intelliserra/intelliserra.png","intelliserra/intelliserra2.png"],"github":"https://github.com/sletizi/IntelliSerra","tags":["scala","functional","iot"]},{"title":"Scanbage","description":"Una potente web app per riconoscere i tipi di spazzatura tramite foto o codice a barre tramite rete convuluzionale (CNN Machine Learning). \nSi tratta di una sorta di social basati su premi sbloccati attraverso la corretta differenziazione dei rifiuti. \nIl progetto è stato realizzato in contesto universitario con Gianluca Aguzzi, Marta Luffarelli e Simone Letizi.\n","thumbnail":"scanbage/thubnail.png","image_gallery":["scanbage/scanbage-pic1.png","scanbage/scanbage-pic2.png","scanbage/scanbage-pic3.png","scanbage/scanbage-pic4.png","scanbage/scanbage-pic5.png"],"tags":["machine learning","cnn","tensorflow","python"]},{"title":"Fluvium","description":"Un sistema full stack per il monitoraggio del livello di innalzamento dei fiumi. Il sistema è stato sviluppato partendo da componenti embedded (ESP32) fino al livello web/cloud basato su AWS. \nIl progetto è realizzato in contesto universitario con Gianluca Aguzzi.\n","thumbnail":"fluvium/thubnail.png","image_gallery":["fluvium/screen1.png","fluvium/screen2.png","fluvium/screen3.png"],"github":"https://github.com/sbricco-house/fluvium","tags":["aws","iot","embedded","cloud"]},{"title":"Subspedia","description":"Applicazione Android sviluppata per <a target=_blank href=https://www.subspedia.tv/> subspedia.tv</a>. \nPermette la gestione delle loro serie TV preferite e il download dei sottotitoli prodotti dalla comunità Subpsedia.\n","thumbnail":"subspedia/thubnail.png","image_gallery":["subspedia/pic1.png","subspedia/pic2.png","subspedia/pic3.png","subspedia/pic4.png"],"tags":["android","tv series","java"]}],"_id":"content:it:projects.yaml","_type":"yaml","title":"Projects","_source":"content","_file":"it/projects.yaml","_stem":"it/projects","_extension":"yaml"}],"navigation":[{"title":"Blog","_path":"/blog","children":[{"title":"Design Distributed Scheduler - I","_path":"/blog/design-distributed-scheduler-1","children":[{"title":"Design Distributed Scheduler - I","_path":"/blog/design-distributed-scheduler-1"}]},{"title":"Hello!","_path":"/blog/hello","children":[{"title":"Hello!","_path":"/blog/hello"}]}]},{"title":"En","_path":"/en","children":[{"title":"Experiences","_path":"/en/experiences"},{"title":"Projects","_path":"/en/projects"}]},{"title":"It","_path":"/it","children":[{"title":"Experiences","_path":"/it/experiences"},{"title":"Projects","_path":"/it/projects"}]}]}